#! /usr/bin/env python3
"""
This script was written to help you find functions you wrote in that script
you have no idea what_was_the_name and where_it_was.

It builds a database with function definitions from all python files
and can be used to fuzzymatch the name of a function

For the fuzzy match it uses fuzzywuzzy if available or the built in difflib
"""

import functools
import os
import collections
import pickle
import glob
import time

import argparse

try:
    from fuzzywuzzy import fuzz
    def ratio(string1, string2):
        """ calculates fuzzy-similarility value (0,1). It uses fuzzywuzzy."""
        return fuzz.ratio(string1, string2)/100
except ImportError:
    from difflib import SequenceMatcher as SM
    def ratio(string1, string2):
        """ calculates fuzzy-similarility value (0,1). It uses difflib."""
        ratio_val = SM(None, string1, string2).ratio()
        return round(ratio_val, 1)


## MODIFIABLE VARIABLES ##
DATABASE_DEFAULT_NAME = os.path.join(os.getenv("HOME"), ".python_functions")
JUNK = " _"

# needed for faster than regex replacement "a b_c".translate(JUNK_DICT)->'abc'
JUNK_DICT = str.maketrans(dict((key, None) for key in JUNK))


def get_cmd(cmd, strip=True):
    """ returns output from command executed in shell """
    shell = os.popen(cmd)
    ret = shell.readlines()
    shell.close()
    if strip:
        ret = [x.strip() for x in ret]
    return ret

def find_defs_in_file(fname):
    """
    finds all "def fname (something)" in a given file
    It returns a list of string (or None)
    """
    try:
        lines_with_def = []
        with open(fname, "r") as fhandle:
            for line in fhandle.readlines():
                if line.find("def ") > -1:
                    lines_with_def.append(line.strip())
        lines_with_def = [line.replace("def ", "") for line in lines_with_def]
        ret = [line[:line.find("(")] for line in lines_with_def]
        # maybe would make sense not to include very short names ...
        # ret = [funcname for funcname in ret if len(funcname)>2]
    except:
        ret = None
    return ret

def find_files(folder=os.path.sep):
    """
    Finds all files in folder.
    If avaliable it uses 'locate' (faster because file list is cached in databse)
    If not, recursive glob is used
    """
    if folder[-1] != os.path.sep:
        folder += os.path.sep

    # try with locate first, will be empty list if it does not exist
    files = get_cmd("locate '*.py'", strip=True)
    if len(files) == 0:
        temp = folder + "**" + os.path.sep + "*.py"
        files = glob.glob(temp, recursive=True)
    else:
        files = [f for f in files if f.find(folder) > -1]
    return files

def update_databse(folder="/", dbase_name=DATABASE_DEFAULT_NAME):
    """
    Creates database of all files in folder and saves in dbase_name as pickle
    """
    container = collections.OrderedDict()
    files = find_files(folder=folder)
    t_start = time.time()
    for fname in files:
        func_names = find_defs_in_file(fname)
        if func_names is not None:
            container[fname] = find_defs_in_file(fname)
    t_end = time.time()
    t_delta = t_end-t_start
    print("# time needed for database bulding in %.1fs (for %d files)"%\
         (t_delta, len(files)))
    with open(dbase_name, 'wb') as storage_file:
        pickle.dump(container, storage_file, pickle.HIGHEST_PROTOCOL)

# here the caching is useful if we use the module as library ...
# we can read the database several times
@functools.lru_cache(maxsize=None)
def read_database(dbase_name):
    """
    read database, result is cached (functool.lru_cache) to speed up multiple
    readings when used as library ...
    """
    if not os.path.isfile(dbase_name):
        print("Could not find database %s, did you create it (--update)"%dbase_name)
        os.sys.exit(1)
    with open(dbase_name, 'rb') as fhandle:
        data = pickle.load(fhandle)
    return data

@functools.lru_cache(maxsize=4096)
def match_func_name(funcname, string_var):
    """
    returns value of matching (0-1). The reason for being a function is that the
    result is cached (the same function name is likely to appear in many files).
    In my test caching speeds the match by a factor ~2
    """
    return ratio(funcname, string_var)

def clean_string(string_var, junk=JUNK_DICT):
    """
    Removes junk characters and brings to lower. Help comparison.
    # Notes junk has to be a dict generated by str.maketrans
    # junk = "#!", junk_dict = dict( (junk_char,None) for junk_char in junk)
    # junk_dict = str.maketrans(junkdict);
    # it translate char to char_num
    """
    return string_var.translate(junk).lower()


def match_all_files(input_string, path=os.path.sep, ncharmin=2, lim=0.7,
                    dbase_name=DATABASE_DEFAULT_NAME, verbose=True):
    """
    Main workhorse, compares input_string with all function names in database
    If verbose it prints the results on screen

    it does not include function names less than ncharmin
    path, limits the search to given subfolder
          (not sure how it handles symlink folders)
    lim, is the minimum matching ratio to consider

    """
    input_string = clean_string(input_string)
    data = read_database(dbase_name)
    res = dict()
    t_start = time.time()
    for fname, func_names in data.items():
        if func_names is None or fname.find(path) == -1:
            continue
        for func_name in func_names:
            if len(func_name) < ncharmin:
                continue
            ratio_val = match_func_name(clean_string(func_name), input_string)
            if ratio_val > lim:
                res[fname+":"+func_name] = ratio_val
    if verbose:
        for func in sorted(res, key=res.get):
            print("%03s %s"%(res[func], func))
        t_delta = time.time()-t_start
        print("# time needed %.2fs (for %d files)"%(t_delta, len(data)))
    return sorted(res, key=res.get, reverse=True)


def main():
    """ function called when used from command line """
    parser = argparse.ArgumentParser(description='Find a python function !',
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    parser.add_argument('--update', action="store_true",
                        help='update database')
    parser.add_argument('--path', type=str, default=os.getenv("HOME"),
                        help='folder to limit the search')
    parser.add_argument('--databse', type=str, default=DATABASE_DEFAULT_NAME,
                        help='filename of databse')
    parser.add_argument('string', metavar='string', type=str, nargs='*',
                        help='string to match')

    args = parser.parse_args()
    if args.update:
        update_databse(folder="/", dbase_name=args.databse)
    if len(args.string) > 0:
        for string in args.string:
            match_all_files(string, path=args.path)
    else:
        parser.print_usage()

if __name__ == "__main__":
    main()
    
